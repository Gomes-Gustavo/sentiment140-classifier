{"cells":[{"cell_type":"markdown","metadata":{"id":"DXBNSy_Fb7Lz"},"source":["# LSTM Training for Sentiment Classification (Google Colab)\n","\n","This notebook was implemented and executed in **Google Colab** in order to take advantage of GPU acceleration for Deep Learning training.  \n","Here, we load tweet embeddings generated previously with Word2Vec and use them to train an LSTM model for sentiment classification.  "]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2521,"status":"ok","timestamp":1744637911201,"user":{"displayName":"Gustavo Gomes","userId":"14634128939275858950"},"user_tz":180},"id":"BkBuJgL4hNTY","outputId":"49f737c5-b4a3-4b46-d866-2a927ece6d7f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"]}],"source":["!pip install tensorflow"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1744637860398,"user":{"displayName":"Gustavo Gomes","userId":"14634128939275858950"},"user_tz":180},"id":"5rdCqV63b63k"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout\n","from sklearn.model_selection import train_test_split\n","import ast\n","from keras.layers import BatchNormalization\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau"]},{"cell_type":"markdown","metadata":{"id":"-87glw0Xb9-P"},"source":["## Mounting Google Drive\n","\n","We mount Google Drive to access the dataset (`sentiment140_vectors.csv`)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8302,"status":"ok","timestamp":1744636732040,"user":{"displayName":"Gustavo Gomes","userId":"14634128939275858950"},"user_tz":180},"id":"0QWjJ2Dsb_a3","outputId":"1553ae09-b0f3-4ef2-9070-97bae993b61d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"pKM4Nqg_cCpn"},"source":["## Loading the Dataset with Tweet Embeddings\n","\n","We load the CSV file containing tweet vectors and sentiment labels.\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":484725,"status":"ok","timestamp":1744637218044,"user":{"displayName":"Gustavo Gomes","userId":"14634128939275858950"},"user_tz":180},"id":"BeHwcNRUcBne"},"outputs":[],"source":["data_path = \"/content/drive/MyDrive/sentiment140-project/data/sentiment140_vectors.csv\"\n","df = pd.read_csv(data_path)\n","\n","# Convert string representation of vectors into actual lists\n","df[\"vector\"] = df[\"vector\"].apply(ast.literal_eval)"]},{"cell_type":"markdown","metadata":{"id":"8U0sDYXce2ig"},"source":["## Preparing Input and Labels\n","\n","We reshape the input to match the expected format of LSTM:  \n","`(samples, timesteps, features)`\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":16405,"status":"ok","timestamp":1744637271686,"user":{"displayName":"Gustavo Gomes","userId":"14634128939275858950"},"user_tz":180},"id":"so1Bqch6e4c2"},"outputs":[],"source":["X = np.vstack(df[\"vector\"].values).astype(np.float32)\n","y = df[\"sentiment\"].values\n","\n","# Reshape to (samples, 1 timestep, vector_size)\n","X = X.reshape((X.shape[0], 1, X.shape[1]))\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1744637431211,"user":{"displayName":"Gustavo Gomes","userId":"14634128939275858950"},"user_tz":180},"id":"FVmoTkRFfmoN","outputId":"a7d4ba50-2e6d-4156-c110-6d47d76abbad"},"outputs":[{"name":"stdout","output_type":"stream","text":["(1581466, 1, 100)\n","(1581466,)\n"]}],"source":["print(X.shape)\n","print(y.shape)"]},{"cell_type":"markdown","metadata":{"id":"cbPrBb3lfz5n"},"source":["## Splitting Data into Training and Validation Sets\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":942,"status":"ok","timestamp":1744637493727,"user":{"displayName":"Gustavo Gomes","userId":"14634128939275858950"},"user_tz":180},"id":"ZKbJGkxof1Ar"},"outputs":[],"source":["X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"]},{"cell_type":"markdown","metadata":{"id":"KDFX9WQWf7Jg"},"source":["## Building the LSTM Model\n","\n","We define a sequential LSTM model with two layers.  \n","Dropout and BatchNormalization are used to improve generalization.  \n","The final Dense layer uses a sigmoid activation to perform binary classification.\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":80,"status":"ok","timestamp":1744637996347,"user":{"displayName":"Gustavo Gomes","userId":"14634128939275858950"},"user_tz":180},"id":"YSC2-VCuf7lu","outputId":"39eb7346-092d-4722-c386-093e02f54bad"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]}],"source":["model = Sequential([\n","    LSTM(128, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),\n","    BatchNormalization(),\n","    Dropout(0.3),\n","\n","    LSTM(64),\n","    BatchNormalization(),\n","    Dropout(0.3),\n","\n","    Dense(1, activation=\"sigmoid\")\n","])"]},{"cell_type":"markdown","metadata":{"id":"syRgHkTkh0Y7"},"source":["## Compiling the Model\n","\n","We compile the model using binary crossentropy loss and the Adam optimizer.  \n","Accuracy will be used as the main evaluation metric.\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":38,"status":"ok","timestamp":1744638011539,"user":{"displayName":"Gustavo Gomes","userId":"14634128939275858950"},"user_tz":180},"id":"riKF4DTUh0yl"},"outputs":[],"source":["model.compile(\n","    loss=\"binary_crossentropy\",\n","    optimizer=\"adam\",\n","    metrics=[\"accuracy\"]\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"Iig-dJhTh33e"},"source":["## Setting up Callbacks\n","\n","We use EarlyStopping to prevent overfitting, and ReduceLROnPlateau to lower the learning rate when the model stagnates.\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":63,"status":"ok","timestamp":1744638041736,"user":{"displayName":"Gustavo Gomes","userId":"14634128939275858950"},"user_tz":180},"id":"AvINuWF1h9LK"},"outputs":[],"source":["callbacks = [\n","    EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n","    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2)\n","]"]},{"cell_type":"markdown","metadata":{"id":"I2PL1_Mph_Ch"},"source":["## Training the Model\n","\n","We train the model using 80% of the data for training and 20% for validation.  \n","This step may take a few minutes depending on dataset size and available resources.\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2213133,"status":"ok","timestamp":1744640624621,"user":{"displayName":"Gustavo Gomes","userId":"14634128939275858950"},"user_tz":180},"id":"J3SZefWNivSU","outputId":"5568a90d-d995-468c-85cc-4946a20d13a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m19769/19769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 10ms/step - accuracy: 0.7457 - loss: 0.5128 - val_accuracy: 0.7626 - val_loss: 0.4862 - learning_rate: 0.0010\n","Epoch 2/10\n","\u001b[1m19769/19769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 10ms/step - accuracy: 0.7565 - loss: 0.4974 - val_accuracy: 0.7658 - val_loss: 0.4814 - learning_rate: 0.0010\n","Epoch 3/10\n","\u001b[1m19769/19769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 10ms/step - accuracy: 0.7593 - loss: 0.4927 - val_accuracy: 0.7685 - val_loss: 0.4769 - learning_rate: 0.0010\n","Epoch 4/10\n","\u001b[1m19769/19769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 10ms/step - accuracy: 0.7615 - loss: 0.4899 - val_accuracy: 0.7700 - val_loss: 0.4743 - learning_rate: 0.0010\n","Epoch 5/10\n","\u001b[1m19769/19769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 10ms/step - accuracy: 0.7625 - loss: 0.4875 - val_accuracy: 0.7714 - val_loss: 0.4726 - learning_rate: 0.0010\n","Epoch 6/10\n","\u001b[1m19769/19769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 10ms/step - accuracy: 0.7646 - loss: 0.4847 - val_accuracy: 0.7712 - val_loss: 0.4726 - learning_rate: 0.0010\n","Epoch 7/10\n","\u001b[1m19769/19769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 10ms/step - accuracy: 0.7660 - loss: 0.4827 - val_accuracy: 0.7723 - val_loss: 0.4719 - learning_rate: 0.0010\n","Epoch 8/10\n","\u001b[1m19769/19769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 10ms/step - accuracy: 0.7663 - loss: 0.4818 - val_accuracy: 0.7725 - val_loss: 0.4706 - learning_rate: 0.0010\n","Epoch 9/10\n","\u001b[1m19769/19769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 10ms/step - accuracy: 0.7660 - loss: 0.4816 - val_accuracy: 0.7728 - val_loss: 0.4700 - learning_rate: 0.0010\n","Epoch 10/10\n","\u001b[1m19769/19769\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 10ms/step - accuracy: 0.7679 - loss: 0.4803 - val_accuracy: 0.7727 - val_loss: 0.4698 - learning_rate: 0.0010\n"]}],"source":["history = model.fit(\n","    X_train, y_train,\n","    validation_data=(X_val, y_val),\n","    epochs=10,\n","    batch_size=64,\n","    callbacks=callbacks\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"VayLhdc7i1zt"},"source":["## Saving the Trained Model\n","\n","We save the trained LSTM model to Google Drive.\n","However, the final model file has already been uploaded to the project's `models/` directory for organization and versioning.  "]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":199,"status":"ok","timestamp":1744640880345,"user":{"displayName":"Gustavo Gomes","userId":"14634128939275858950"},"user_tz":180},"id":"YUqnyd0Hi2sv","outputId":"3460f08d-b7d7-4dad-ac77-9fb03fa7af14"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"name":"stdout","output_type":"stream","text":["Model saved to /content/drive/MyDrive/sentiment140-project/models/lstm_sentiment140.h5\n"]}],"source":["model_path = \"/content/drive/MyDrive/sentiment140-project/models/lstm_sentiment140.h5\"\n","model.save(model_path)\n","print(f\"Model saved to {model_path}\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOLxlIghkoGRFl/5ipdAaOS","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.7"}},"nbformat":4,"nbformat_minor":0}
